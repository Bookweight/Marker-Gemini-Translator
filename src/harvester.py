import re
import json
import logging
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional

# å¼•å…¥ä¹‹å‰çš„ Clientï¼Œå› ç‚ºæˆ‘å€‘éœ€è¦å»æŠ“å–é‚£äº›è¢«è©•åˆ†è«–æ–‡çš„ Vector
from src.client import S2Client

class ProfileManager:
    """
    ä½¿ç”¨è€…ç•«åƒç®¡ç†å™¨
    åŠŸèƒ½: ç®¡ç† user_profile.jsonï¼ŒåŸ·è¡Œ Rocchio å‘é‡æ›´æ–°
    """
    def __init__(self, data_dir: str = "data"):
        self.logger = logging.getLogger(__name__)
        self.data_path = Path(data_dir)
        self.profile_file = self.data_path / "user_profile.json"
        self.data_path.mkdir(exist_ok=True)
        
        # è¼‰å…¥æˆ–åˆå§‹åŒ– Profile
        self.profile = self._load_profile()

    def _load_profile(self) -> Dict[str, Any]:
        if self.profile_file.exists():
            try:
                with open(self.profile_file, 'r') as f:
                    data = json.load(f)
                    # JSONå­˜çš„æ˜¯ listï¼Œè½‰å› numpy array
                    if data.get('user_vector'):
                        data['user_vector'] = np.array(data['user_vector'])
                    return data
            except Exception as e:
                self.logger.error(f"è®€å– Profile å¤±æ•—: {e}ï¼Œå°‡é‡ç½®ã€‚")
        
        # é è¨­ Profile
        return {
            "user_vector": None,       # åˆå§‹ç‚º None (å†·å•Ÿå‹•)
            "rated_paper_ids": [],     # ç´€éŒ„å·²è©•åˆ†çš„ IDï¼Œé¿å…é‡è¤‡è¨“ç·´
            "total_ratings": 0
        }

    def save_profile(self):
        """å°‡ Profile å¯«å› JSON (Numpy array éœ€è½‰ list)"""
        data_to_save = self.profile.copy()
        if data_to_save['user_vector'] is not None:
            data_to_save['user_vector'] = data_to_save['user_vector'].tolist()
        
        with open(self.profile_file, 'w') as f:
            json.dump(data_to_save, f, indent=2)

    def update_vector(self, paper_vector: List[float], rating: int):
        """
        Rocchio æ¼”ç®—æ³•æ ¸å¿ƒ [cite: 76-78]
        Rating æ˜ å°„é‚è¼¯:
          1-3 åˆ† (è² é¢): æ¨é›¢ (-0.5 ~ -1.0)
          4-6 åˆ† (å¿½ç•¥): æ¬Šé‡ 0 (è¦–ç‚ºé›œè¨Š)
          7-10 åˆ† (æ­£é¢): æ‹‰è¿‘ (+0.5 ~ +1.0)
        """
        # 1. å®šç¾©æ¬Šé‡ w
        if rating <= 3:
            weight = -0.5  # è² é¢
        elif 4 <= rating <= 6:
            weight = 0.0   # å¿½ç•¥
            self.logger.info(f"Rating {rating} è¦–ç‚ºä¸­ç«‹ï¼Œè·³éæ›´æ–°ã€‚")
            return
        else:
            weight = 1.0   # æ­£é¢ (7-10)

        paper_vec = np.array(paper_vector)
        user_vec = self.profile['user_vector']

        # 2. å†·å•Ÿå‹•è™•ç†ï¼šå¦‚æœæ˜¯ç¬¬ä¸€å€‹è©•åˆ†ï¼Œç›´æ¥æŠŠè«–æ–‡å‘é‡ç•¶æˆä½¿ç”¨è€…å‘é‡
        if user_vec is None:
            self.logger.info("å†·å•Ÿå‹•: åˆå§‹åŒ–ä½¿ç”¨è€…å‘é‡")
            self.profile['user_vector'] = paper_vec
            return

        # 3. Rocchio æ›´æ–°å…¬å¼: u_new = u_old + learning_rate * weight * (d - u_old)
        # éš¨è‘—è©•åˆ†æ¬¡æ•¸å¢åŠ ï¼ŒLearning Rate é€æ¼¸é™ä½ (0.1 -> 0.01) ä»¥ä¿æŒç©©å®š
        n = self.profile['total_ratings']
        learning_rate = max(0.01, 0.1 * (0.95 ** n)) 
        
        # å‘é‡åŠ æ¬Šç§»å‹•
        new_vec = user_vec + learning_rate * weight * (paper_vec - user_vec)
        
        # æ­£è¦åŒ– (Optional but recommended for Cosine Sim)
        norm = np.linalg.norm(new_vec)
        if norm > 0:
            new_vec = new_vec / norm
            
        self.profile['user_vector'] = new_vec
        self.profile['total_ratings'] += 1
        self.logger.info(f"å‘é‡å·²æ›´æ–° (Rating: {rating}, Weight: {weight}, LR: {learning_rate:.4f})")


class NoteHarvester:
    """
    ç­†è¨˜æ”¶å‰²è€…
    åŠŸèƒ½: æƒæ Obsidian ç­†è¨˜ï¼Œæå–è©•åˆ†
    """
    def __init__(self, config: Dict[str, Any], client: S2Client, profile_manager: ProfileManager):
        self.logger = logging.getLogger(__name__)
        self.config = config
        self.client = client
        self.pm = profile_manager
        
        vault_path = Path(self.config['obsidian']['vault_path'])
        daily_folder = self.config['obsidian'].get('daily_folder', '')
        self.search_path = vault_path / daily_folder

    def harvest(self, lookback_days: int = 7):
        """æƒæéå» N å¤©çš„ç­†è¨˜"""
        self.logger.info(f"ğŸŒ¾ é–‹å§‹æ”¶å‰²éå» {lookback_days} å¤©çš„è©•åˆ†...")
        
        today = datetime.now()
        found_ratings = []

        # 1. éæ­·æ—¥æœŸæª”æ¡ˆ
        for i in range(lookback_days):
            date_str = (today - timedelta(days=i)).strftime("%Y-%m-%d")
            note_path = self.search_path / f"{date_str}.md"
            
            if note_path.exists():
                ratings = self._parse_note(note_path)
                found_ratings.extend(ratings)
        
        self.logger.info(f"å…±ç™¼ç¾ {len(found_ratings)} å€‹è©•åˆ†æ¨™è¨˜")

        # 2. éæ¿¾å·²è™•ç†éçš„è©•åˆ†
        processed_ids = set(self.pm.profile['rated_paper_ids'])
        new_ratings = [r for r in found_ratings if r['paper_id'] not in processed_ids]
        
        if not new_ratings:
            self.logger.info("æ²’æœ‰æ–°çš„è©•åˆ†éœ€è¦è™•ç†ã€‚")
            return

        self.logger.info(f"æº–å‚™è™•ç† {len(new_ratings)} å€‹æ–°è©•åˆ†...")
        
        # 3. ç²å–å‘é‡ä¸¦æ›´æ–°
        # ç‚ºäº†ç¯€çœ APIï¼Œæˆ‘å€‘å°‡ ID æ”¶é›†èµ·ä¾†ä¸€æ¬¡æŠ“å– (Batch)
        ids_to_fetch = [r['paper_id'] for r in new_ratings]
        paper_details = self.client.get_batch_details(ids_to_fetch)
        
        # å»ºç«‹ ID -> Embedding çš„æŸ¥è¡¨
        embedding_map = {p['paperId']: p.get('embedding', {}).get('specter_v2') for p in paper_details}
        
        # 4. åŸ·è¡Œæ›´æ–°
        for item in new_ratings:
            p_id = item['paper_id']
            score = item['score']
            vec = embedding_map.get(p_id)
            
            if vec:
                self.pm.update_vector(vec, score)
                self.pm.profile['rated_paper_ids'].append(p_id)
            else:
                self.logger.warning(f"ç„¡æ³•ç²å–è«–æ–‡ {p_id} çš„å‘é‡ï¼Œè·³éæ›´æ–°")

        # 5. å­˜æª”
        self.pm.save_profile()
        self.logger.info("âœ… ä½¿ç”¨è€…ç•«åƒæ›´æ–°å®Œæˆï¼")

    def _parse_note(self, file_path: Path) -> List[Dict]:
        """
        è§£æå–®ä¸€ Markdown æª”æ¡ˆ
        å°‹æ‰¾çµæ§‹:
           - [Open on Semantic Scholar](.../paper/{paperId})
           - **Rating**: (9)
        """
        content = file_path.read_text(encoding='utf-8')
        results = []
        
        # ä½¿ç”¨ Regex æ•æ‰ï¼šå…ˆæŠ“ URL è£¡çš„ IDï¼Œå†å¾€ä¸‹æ‰¾æœ€è¿‘çš„ Rating
        # æ³¨æ„ï¼šé€™å€‹ Regex å‡è¨­ Link å’Œ Rating åœ¨åŒä¸€å€‹å€å¡Š (æˆ‘å€‘çš„ Writer æ˜¯é€™æ¨£å¯«çš„)
        
        # æ­¥é©Ÿ A: å°‡å…§å®¹ä¾æ“š "- [ ]" åˆ†å‰²æˆå¡ç‰‡å€å¡Šï¼Œé¿å…è·¨è«–æ–‡èª¤åˆ¤
        cards = re.split(r'- \[.\] \*\*', content)
        
        for card in cards:
            # 1. æå– ID
            id_match = re.search(r'semanticscholar\.org/paper/([a-f0-9]+)', card)
            # 2. æå–åˆ†æ•¸ (æ”¯æ´ (9), ( 9 ), (10))
            score_match = re.search(r"Rating\**:\s*\(\s*(\d+)\s*\)", card)
            
            if id_match and score_match:
                paper_id = id_match.group(1)
                score = int(score_match.group(1))
                
                # åˆç†æ€§æª¢æŸ¥ (1-10åˆ†)
                if 1 <= score <= 10:
                    results.append({'paper_id': paper_id, 'score': score})
        
        return results