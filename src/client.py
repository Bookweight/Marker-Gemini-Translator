import logging
import time
from typing import Any, Dict, List, Optional, cast

import requests
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential,
)


class S2Client:
    """
    Semantic Scholar API å®¢æˆ¶ç«¯ (Engineering Grade)

    ç‰¹é»:
    1. Type Hinting: å…¨é¢å‹åˆ¥æç¤ºï¼Œæå‡é–‹ç™¼é«”é©—èˆ‡é™¤éŒ¯æ•ˆç‡ã€‚
    2. Config Driven: åƒæ•¸ä¸å¯«æ­»ï¼Œä¾è³´å‚³å…¥çš„ config å­—å…¸ã€‚
    3. Logging: ä½¿ç”¨ logger å–ä»£ printï¼Œæ”¯æ´æª”æ¡ˆç´€éŒ„ã€‚
    4. Resilience: å…§å»º Rate Limit ä¿è­·èˆ‡æŒ‡æ•¸é€€é¿é‡è©¦æ©Ÿåˆ¶ã€‚
    """

    BASE_URL = "https://api.semanticscholar.org/graph/v1"

    def __init__(self, api_key: Optional[str], config: Dict[str, Any]):
        """
        åˆå§‹åŒ–å®¢æˆ¶ç«¯

        :param api_key: å¾ç’°å¢ƒè®Šæ•¸è®€å–çš„ API Key
        :param config: å¾ config.yaml è®€å–çš„è¨­å®šå­—å…¸
        """
        self.logger = logging.getLogger(__name__)  # å–å¾—ç•¶å‰æ¨¡çµ„çš„ logger
        self.api_key = api_key
        self.config = config

        # è¨­å®š Headers
        self.headers = {}
        if self.api_key:
            self.headers["x-api-key"] = self.api_key
        else:
            self.logger.warning(
                "æœªåµæ¸¬åˆ° API Keyï¼Œå°‡ä»¥æœªèªè­‰æ¨¡å¼é‹ä½œ (Rate Limit æ¥µä½)"
            )

        # å¾è¨­å®šæª”è®€å–åƒæ•¸ (è¨­æœ‰é è¨­å€¼ä»¥é˜² config ç¼ºæ¼)
        self.batch_size = self.config.get("api", {}).get("batch_size", 50)
        self.rate_limit_sleep = self.config.get("api", {}).get("sleep_seconds", 1.1)

    @retry(
        stop=stop_after_attempt(5),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type(requests.exceptions.RequestException),
        reraise=True,
    )
    def _make_request(
        self,
        method: str,
        endpoint: str,
        params: Optional[Dict] = None,
        json_data: Optional[Dict] = None,
    ) -> Any:
        """
        ç™¼é€ HTTP è«‹æ±‚çš„åº•å±¤å‡½å¼ (Private Method)
        """
        url = f"{self.BASE_URL}{endpoint}"

        # å¼·åˆ¶å†·å»ï¼šéµå®ˆ Rate Limit
        time.sleep(self.rate_limit_sleep)

        try:
            self.logger.debug(f"ç™¼é€è«‹æ±‚: {method} {url}")

            if method == "GET":
                response = requests.get(url, headers=self.headers, params=params)
            elif method == "POST":
                response = requests.post(
                    url, headers=self.headers, params=params, json=json_data
                )
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„ HTTP æ–¹æ³•: {method}")

            # è™•ç† 429 Too Many Requests
            if response.status_code == 429:
                self.logger.warning("âš ï¸ è§¸ç™¼ Rate Limit (429)ï¼ŒTenacity å°‡æ¥æ‰‹é‡è©¦...")
                raise requests.exceptions.RequestException("Rate Limit Hit")

            response.raise_for_status()
            return response.json()

        except requests.exceptions.RequestException as e:
            self.logger.error(f"API è«‹æ±‚å¤±æ•—: {e} | URL: {url}")
            raise  # æ‹‹å‡ºè®“ Tenacity æ•ç²

    def search_papers(
        self, query: str, year_range: str, limit: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        æœå°‹å€™é¸è«–æ–‡ (Discovery Layer)

        :param query: æœå°‹é—œéµå­— (å¦‚ "Deep Learning")
        :param year_range: å¹´ä»½ç¯„åœ (å¦‚ "2020-2025")
        :param limit: æœå°‹æ•¸é‡ (è‹¥æœªæŒ‡å®šå‰‡è®€å– config)
        :return: åŒ…å«åŸºç¤è³‡è¨Šçš„è«–æ–‡åˆ—è¡¨
        """
        endpoint = "/paper/search"

        # è‹¥æœªæŒ‡å®š limitï¼Œå‰‡å¾ config è®€å–ï¼Œé è¨­ 20
        search_limit = limit or self.config.get("search", {}).get("limit", 20)

        params = {
            "query": query,
            "year": year_range,
            "limit": search_limit,
            "fields": "paperId,title,fieldsOfStudy,year",  # åªæŠ“éæ¿¾éœ€è¦çš„æ¬„ä½
        }

        self.logger.info(
            f"åŸ·è¡Œæœå°‹: Query='{query}', Year='{year_range}', Limit={search_limit}"
        )

        data = self._make_request("GET", endpoint, params=params)
        papers = cast(List[Dict[str, Any]], data.get("data", []))

        self.logger.info(f"æœå°‹å®Œæˆï¼Œå…±æ‰¾åˆ° {len(papers)} ç¯‡å€™é¸è«–æ–‡")
        return papers

    def get_batch_details(self, paper_ids: List[str]) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡ç²å–è©³ç´°è³‡æ–™ (Enrichment Layer)

        :param paper_ids: è«–æ–‡ ID åˆ—è¡¨
        :return: åŒ…å« Embedding èˆ‡å¼•ç”¨æ•¸çš„è©³ç´°è³‡æ–™åˆ—è¡¨
        """
        if not paper_ids:
            return []

        endpoint = "/paper/batch"

        # æŒ‡å®šéœ€è¦çš„æ¬„ä½
        fields = "paperId,title,year,influentialCitationCount,citationCount,fieldsOfStudy,abstract,embedding.specter_v2,openAccessPdf,externalIds,venue,publicationVenue,journal"

        params = {"fields": fields}

        all_details = []
        total_batches = (len(paper_ids) + self.batch_size - 1) // self.batch_size

        self.logger.info(
            f"ğŸ“¥ é–‹å§‹æ‰¹é‡ä¸‹è¼‰è©³æƒ…: {len(paper_ids)} ç¯‡è«–æ–‡ï¼Œåˆ† {total_batches} æ‰¹æ¬¡è™•ç†"
        )

        for i in range(0, len(paper_ids), self.batch_size):
            chunk = paper_ids[i : i + self.batch_size]
            payload = {"ids": chunk}

            try:
                self.logger.debug(
                    f"è™•ç†æ‰¹æ¬¡ {i // self.batch_size + 1}/{total_batches} (Size: {len(chunk)})"
                )
                result = self._make_request(
                    "POST", endpoint, params=params, json_data=payload
                )

                if result:
                    # éæ¿¾ None (S2 æœ‰æ™‚æœƒå›å‚³æ‰¾ä¸åˆ°çš„ ID ç‚º None)
                    valid_items = [p for p in result if p is not None]
                    all_details.extend(valid_items)
            except Exception as e:
                self.logger.error(f"æ‰¹æ¬¡è™•ç†å¤±æ•— (Index {i}): {e}")
                # é¸æ“‡ï¼šé€™è£¡å¯ä»¥æ±ºå®šè¦ä¸­æ–·é‚„æ˜¯ç¹¼çºŒ (ç›®å‰ç­–ç•¥æ˜¯ç´€éŒ„éŒ¯èª¤ä¸¦ç¹¼çºŒ)
                continue

        self.logger.info(f"æ‰¹é‡ä¸‹è¼‰å®Œæˆï¼ŒæˆåŠŸç²å– {len(all_details)} ç¯‡è«–æ–‡è©³æƒ…")
        return all_details
